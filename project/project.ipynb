{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2fb019b-f01c-48be-af41-880d64fa9bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "334eadda-30b6-4a83-838e-d728719ef1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import scipy.io.wavfile\n",
    "from scipy.fftpack import fft, fftfreq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3be33b-87ae-4d56-a1ab-0cbd2d74daad",
   "metadata": {},
   "source": [
    "# Error-Correcting Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723f31f0-2b9b-4f0b-84fa-bc0c9fd1b6b8",
   "metadata": {},
   "source": [
    "## What are Error-Correcting codes and why are they so important?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32285c82-0813-4593-bcdf-3c01b83d138c",
   "metadata": {},
   "source": [
    "In the era of communications, it is always important the data to be transferred in a secure and looseless way. But we still cannot make the technologies so perfect, and sometime times part of the data can be lost during the transfer. \n",
    "So what can we do in order to check whether there are errors in data transmission over noisy or unreliable communications channels?\n",
    "For example, we can generate a hashcode of the transferred data (using MD5, SHA256 or some other algorithm), and provide it together with the transferred data. If there is difference between the generated hashcode, and the hashcode, that we calculate at the final point of the transfer, we shall know, that there is difference between the original data, and the data that we received (some transfer loss, some intended change in the data being transferred).\n",
    "If the content of the data is not so important for us, we can even just make a checksum - for example summing the numbers of the bytes to be transferred, and this sum will be transferred together with the data.  After the data is transferred, the checksum is calculated again, and if it is the same as the provided one, then we consider, that the transferred data is intact.\n",
    "Ok, until now we found two easy ways to find that there was an error/problem during the data transmission. But what is the biggest problem with them?\n",
    "The biggest problem is, that even if we find out, that a problem occurred during the data transfer, we can only detect it, but we CANNOT FIX it. And here come the error-correcting codes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7156d85d-6df5-4ed0-9b06-20f326df886b",
   "metadata": {},
   "source": [
    "## What are the different types of error-correcting codes? Provide real-world examples?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adb86bd-06ba-46b9-af7a-6a0654253b14",
   "metadata": {},
   "source": [
    "Linear Block Codes:\r\n",
    "\r\n",
    "Hamming Codes: These are simple and widely used error-correcting codes that can correct single-bit errors and detect two-bit errors.\r\n",
    "BCH Codes (Bose-Chaudhuri-Hocquenghem): These are a class of powerful error-correcting codes that can correct multiple random error patterns.\r\n",
    "Reed-Solomon Codes: These codes are highly effective for correcting burst errors and are commonly used in digital storage and transmission systems, such as CDs, DVDs, and QR codes.\r\n",
    "Convolutional Codes:\r\n",
    "\r\n",
    "These codes are used in real-time error correction and are characterized by their use of convolutional processes to encode data streams. Convolutional codes are widely used in applications like mobile communications and satellite communications.\r\n",
    "Viterbi Algorithm: Often used for decoding convolutional codes, this algorithm finds the most likely sequence of states that result in a given sequence of observed data.\r\n",
    "Turbo Codes:\r\n",
    "\r\n",
    "Turbo codes are a class of high-performance error-correcting codes that achieve near Shannon limit performance. They are used in deep-space communications and 4G/5G mobile networks.\r\n",
    "These codes employ iterative decoding, which significantly improves error-correcting performance.\r\n",
    "Low-Density Parity-Check (LDPC) Codes:\r\n",
    "\r\n",
    "LDPC codes are linear block codes known for their excellent performance close to the Shannon limit. They use sparse matrices and iterative decoding techniques.\r\n",
    "LDPC codes are used in modern communication standards, including Wi-Fi, 5G, and satellite communications.\r\n",
    "Polar Codes:\r\n",
    "\r\n",
    "Polar codes are a type of error-correcting code that can achieve the capacity of binary-input discrete memoryless channels. They are known for their simple structure and efficient decoding algorithms.\r\n",
    "Polar codes have been adopted for use in 5G New Radio (NR) standard.\r\n",
    "Product Codes:\r\n",
    "\r\n",
    "Product codes are constructed by combining two or more simpler codes, usually block codes, to form a larger code with enhanced error-correcting capability.\r\n",
    "They are used in applications where high reliability is required, such as data storage systems.\r\n",
    "Repeat-Accumulate (RA) Codes:\r\n",
    "\r\n",
    "These are a class of codes that combine simple repetition codes with accumulation (or differential encoding) to create more complex codes with good performance.\r\n",
    "RA codes are used in applications where low complexity is essential, like in some wireless communication systems.\r\n",
    "Each of these error-correcting codes has specific advantages and is chosen based on the requirements of the application, such as the nature of the errors (random or burst), the required error correction capability, the complexity of encoding/decoding, and latency constraints.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d28f0-f7e0-4ba4-8032-a2dec603135d",
   "metadata": {},
   "source": [
    "## What is a Hamming code? Describe the history and / or derive the formula(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27458615-c079-4440-827f-646e40857094",
   "metadata": {},
   "source": [
    "## What are parity bits and how do we use them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9931393-3066-4de9-ac0a-2e18eb34a4fe",
   "metadata": {},
   "source": [
    "Let us first begin with this : what is Parity Check? The parity check is a simple error detection technique used to determine whether a binary data set has been altered during transmission or storage. For a parity check, we separate only one single bit, that the sender is responsible for tuning, and the rest bits are free to carry a message. The only job of this single bit is to make sure, that the total number of 1s in this binary data is an even number. For example, if the original binary data is [1101001], here the number of the 1s is 4, which is an even number. So the value of this special bit will be 0 and the transmitted data will be  [11010010] (the orinal data plus the special bit). But if we would like to transfer the data [1111 111], here the number of the 1s is odd, that is why the sender needs to flip that special bit to be 1, in order to make the count even and the transmitted data will be  [1111 1111]. And this special bit is named \"parity bit\". This is pretty simple, but still very elegant way a change anywhere in the binary data to be reflected in a single bit of information.\n",
    "Of course, this is a very simple check - if there are two errors in the transmission, the number of the 1s still will be even, so the parity check will not show us, that there is a problem. Also if the parity check shows an error, it could be not one error, but 3 or 7 or 127. \n",
    "So parity checks on their own are pretty weak, but by distilling the idea of change across full message down to a single bit, give room for more sophisticated schemes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8bdc67-64eb-4b5a-b532-a2e8ce567eec",
   "metadata": {},
   "source": [
    "## What is the Hamming distance and what is its significance? How is it related to other distance metrics for text / bit sequences?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c59eaf1-d101-4e3c-b45c-2efb1fea2a95",
   "metadata": {},
   "source": [
    "Deeper dive into mathematics:\n",
    "Derive the general formula for the number of parity bits required for a given number of data bits.\n",
    "Explain the process of encoding data using Hamming codes. How are parity bits positioned in the data?\n",
    "Describe the process of detecting and correcting errors using Hamming codes. How are syndrome vectors used in this process?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b3eca7-321f-4707-a90e-f0f656010fc0",
   "metadata": {},
   "source": [
    "Let's dive deeper into the mathematics:\n",
    "To determine the number of parity bits required for a given number of data bits in a Hamming code, we need to ensure that the code can detect and correct single-bit errors. The process involves using the parity bits to cover all the data bits and the parity bits themselves. Here's the step-by-step derivation of the formula:\n",
    "let us denote :\n",
    "- d is the number of the data bits\n",
    "- p is the number of the parity bits\n",
    "- n is the total number of bits (n = d + p)\n",
    "For hHamming code, each possible bit possition in the data bits must me uniquely identifiable by the combination of the parity bits. The parity bits can form 2 ** p combinations, and hence, we can conclude that these combinations should be greater that the total number of bits:\n",
    "\n",
    "$$ 2^p >= n $$\n",
    "\n",
    "Looks reasonable, correct? But we forget something - as it can happen, that there are errors in the data transmission, and we would like to be able to identify them uniquely, there is also the opportunity there not to be error at all, and one of the parity bits combinations should be used to indicate no error at all. That is why the condition should be:\n",
    "$$ 2^p >= n + 1$$\n",
    "\n",
    "And as \n",
    "$$ n = d + p $$\n",
    "the formula for required parity bits for a given number of data bits in a Hamming code finally looks like this :\n",
    "$$ 2^p >= d + p + 1 $$\n",
    "\n",
    "Let us check how many parity bits for 10 data bits (d = 10). So we need to find such p, that \n",
    "$$ 2^p >= 10 + p + 1 $$\n",
    "As $2^3$ is  8, obviously we shall need a bigger number. Let is try with $p = 4$. \n",
    "$$ 2^4 = 16 >= 10 + 4 + 1 $$\n",
    "This is true, so obviously for 10 data bits 4 parity bits are sufficient.\n",
    "\n",
    "So generally the method for finding the needed parity bits is :\n",
    "\n",
    "Find the smallest p, that satisfies $ 2^p >= d + p + 1 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94a8722-a68a-4fa7-b9d1-adc531b7fe67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
