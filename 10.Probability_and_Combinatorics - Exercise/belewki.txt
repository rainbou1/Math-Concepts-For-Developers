Какво трябва да съдържа Jupiter Notebook
Какво трябва да съдържа 
Анализ на задачата
Математика
Код

Типичен въпрос : Какво представлява линейна функция.
Изчисляване на първа производна

scientific citation - за цитиране.
В края на jupiter nodes да сложим references.

От задачите:
зад 1
Разпределенията са функции
С точка и запетая дефинираме параметри - те ще са константи при извикването на функцията
Имаме и променливи, и параметри 
f(x ; n, p) ------> f(x) практически си е функция на x

Ще разберем какво правят тези параметри.

Фундаментална Теорема на Аритметиката - всяко едно число може да бъде разложено на прости множители.
Фундаментална Теорема на Алгебрата - Всеки полином от n-та степен с комплексни коефициенти има точно n на брой корена.
Фундаментална Теорема на Анализ - Диференцирането и интегрирането са обратни, ако пренебрегнем загубата на информация при диференциране на константа.
Централна Гранична Теорема - независимо от това какви разпределения имаме, сумата от такива разпределения е гаусово разпределение

зад 2
Третираме функциите като разпределения.

Constraint optimization - оптимизация на определена цена.
Probabilistic Programming Language.

Нека имаме някакво случайноо събитие...въпросът е колко ни изненадва това събитие, когато се случи.
А едно събитие което никога не се случва, никога не ни изненадва.
Едно събитие, което се случва с вероятност 20%, ще ни изненада в 20 случая от 100.
Ако очакваме нещо да се случи 80%, в 80 от 100 ще съм прав и няма да бъда изненадан.
Не е правилно да кажем какво ще стане, защото не знаем какво ще стане.
Колко най-много може да ме изненада едно събитие - най-много може да изненада, ако става с вероятност 50/50.
Количеството изненада, което ни носи едно събитие, за това че се е случило или че не се е случило, може да се пробваме да го представим в някаква функция.
Изненадата я наричаме с I
Максималната изненада е при вероятност 0,5.
Изненадата, която ми е доставила това събитие при случването си, ми носи повече информация за него.
I e information.

Например резултата от ьвърлянето на монета може бъде записан в булева променлива is_heads = True | False
И това може да се запише в 1 бит.

Ако имаме още една монета = вече записваме резултата в 2 бита....и т.н.
Ако имаме 100 монети - 100 бита.
Дървото на Хъфман е оптимален начин за записване на информацията.
Ако монетите не са честни и имаме 90 езита - ще ни трябва по-малко информация.
100 монети имат 2 на степен 100 възможни състояния, и можем да ги запишем в 100 бита.

В n бита може да запишем 2^n състояния.
Ако имаме m състояния, колко бита ни трябват да ги опишем - log2m

Това е информацията, която получаваме - трябва да видим колко е изненадата - информацията, която не получаваме.
Тъй като p e между 0 и 1, 2 на тази степен е < 2.
I = -log2p.
Тя е мярка за това колко разбираме от него.

Голяма изненада означава хаотичност.
Мярката за тази хаотичност се нарича ентропия.
и ако имаме информацията, умножена по вероятността, за това да се случи, получаваме ентропията за тази вероятност.
Полезни са случаите, които имаме средно количество ентропия.


Вероятност по информацият
Ако нещо много ни изненадва и се случва, 
Безпорядък - не само колко информация има, но и колко често се случва.

Условна вероятност.
Information Gain - безпорядъка е намалял. = H (a posteriori) - H (a priori) < 0
Shannon Information, Shannon entropy.

Дискретните дистрибуции са само за цели числа.
scipy.stats - 
chi square се ползва, когато сравняваме категорийни променливи.
np.arange връща само цели числа.

n - брой опити
колкото повече опити - толкова повече са успешни
plt.subplots - няколко графики 

Биномното разпределение идва от много на брой бернули trials.
A Bernoulli trial (or experiment) is a random experiment where there are exactly two possible outcomes: success and failure.
scipy.stats.binom - това което връща е, колко на брой успешни случая ще има, когато имаме n на брой опита и вероятността за всеки от опитите да се случи е p

Гаусово - мю е център на симетрията.
сигма е мярка колко е широко разпределението
сигма на квадрат се нарича дисперсия - разпръсвание.

Сигма ще го наречем стандартно отклонение.
При n клоняшо към безкрайност биномното разпределение става гаусово
pause and ponder.

Централна гранична теорема - вероятностно разпределение и площта под графиката да е = 1
Разпределението на сумите е гаусово

Основната идея на една хешираща функция е да бъде математическа - при един и същи вход, връща един и същи изход.
За да бъде хещираща, искаме информацията на изхода да е с еднаква дължина


Всяка една функция отговаряща на тези условия може да е хешираща.
Резултата се нарича хеш.

Ред на Тейлър е сума от базисни функции
Една функция е представяне като сума на базисни функции
В случая базисните вектори са синуси и косинуси (рисунката на косинусите).
Синуса и косинуса представлява ортонормиран базис.
Дължина на вектор наричаме скаларното произведение на вектора със себе си.

Ако функцията е функция на времето, я наричаме сигнал.
Имаме и амплитуда и честота.
Теорема на nyquist
Анализа на фурие дава възможност да разберем кое участва в този запис
fft - fast furie transform.
Има честоти които са отрицателни.