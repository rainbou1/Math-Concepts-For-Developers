1.Да отворим kaggle.com, отиваме на datasets, харесваме си нещо и поиграем.
Отваряме дейтасета и гледаме какво има в него.
Exploratory Data Analysis - анализ на данни с цел да разберем какво става в тях.
Най-силният инструмент в Data Science.
Метаданни - да знаем за какво са събрани данните.
Целта е да разберем какви полезни неща има в самия dataset.

Входът е данни и метаданни.
Целта е да разберем какво става в тях.Каква информация можем да изведем от тях.
Трябва да имаме някакъв вид ментален модел за данните.

Друга задача:
отваряме:
arxiv.org
paperswithcode.com

харесваме си статия и четем.

От задачите:
Зад. 1 - да видим какви закономерности има и да получим представа за експериментално и теоретично.
Един dataset може да представя много различни гледни точки към едни и същи данни и трябва да можем да разкажем правилната история.
Най-сигурното, което можем да правим, е различни сравнения.
Корелации - връзка или липса на връзка между данните.
Симулации - weather radar simulation. Получаваме данни и искаме да ги екстраполираме за кратък интервал от време. Тези неща зависят от много променливи.
Много по-лесно е да ги облечем в числата, които сме наблюдавали.
Метеорологичното време и други неща са хаотични. Това означава, че всеки път ще получим различни резултати, ама ако направим достатъчно много брой с, ще мога на нещо да разчитам, на някакви типични резултати. Статистиката за веднъж не работи.
Симулацията е и много добър начин за решаване на задачи от статистика и вероятности. 
Най-известния метод е Метода Монте Карло : Задаваме първоначални предположения за системата, правим много на брой симулирани експерименти и получаваме много на брой симулирани данни и търсим в резултатите от тях нешо общо, което можем да репортнем.
Друго е да проверим дали първоначалните съображения са били правилни.
Например искаме да предвидим времето вчера - взимаме данните от предния ден и виждаме къде е разликата между наблюдавано и очаквано и да направим корекции.
Probabilistic Programming - програмиране, в което всяка една променлива има разпределение. Популярни библиотеки. TensorFlow Probability, PyMC . Има още много frameworks, на които основната идея е да правим симулация. 
В статистиката от резултата, смятаме апостериори вероятност (числителя във формулата на бейс.), и на базата на нея получаваме условна. Това е начина по който работи naive bais.

Параметри, правим някаква симулация и наблюдаваме. и от тези наблюдения можем да разберем:
1. Кое ще е следващото наблюдение?
2. Как да си подобрим модела.

Свързана с Monte Carlo е още една концепция, наречена верига на Марков (Markov chain). Често вървят заедно.

Likelyhood - правдоподобие.
Правим някакъв опит и като резултат получаваме една от (евентуално безкрайно) многото стойности на една случайна променлива.
Втори опит - вероятно някаква друга стойност.
Тези стойности имат някакво вероятностно разпределение. Въпросът е какво очакваме от тези стойности? Лошо зададен въпрос, но от един опит очакваме нещо, какво да бъде то?
Стандартно гаусово разпределение използваме. 

Ако трябва да очакваме стойност, коя да бъде тя?
Ми тогава отговаряме - arg max f(x).

Ако имаме дискретна променлива и нейната хистограма.
y ще бъде функция на вероятност.
Probability Mass Function.
1.p(1) + 2.p(2).. = получаваме средно претеглено. 

p(1) = броят на случаите, в които сме получили 1/ броя на всички случаи.
https://www.calculat.org/bg/%D1%81%D1%80%D0%B5%D0%B4%D0%BD%D0%B0-%D1%81%D1%82%D0%BE%D0%B9%D0%BD%D0%BE%D1%81%D1%82/%D1%81%D1%80%D0%B5%D0%B4%D0%BD%D0%BE-%D0%BF%D1%80%D0%B5%D1%82%D0%B5%D0%B3%D0%BB%D0%B5%D0%BD%D0%B0-%D1%81%D1%82%D0%BE%D0%B9%D0%BD%D0%BE%D1%81%D1%82/

Става x1 * брой случаи когато получаваме x1 + x2 * брой случаи когато получаваме x2 + x3 * брой случаи когато получаваме x3 ..../all.

Вместо да правим умножения, взимаме списък с повторенията.
Това е формулата за средно аритметично. 

Нарича се Expected value. На български е математическо очакване. Това е средното аритметично.
Ако имаме няакво разпределение, неговото математическо очакване е идентично на средното аритметично. мю, шото трябва да е за цялата съвкупност.
Средното аритметично се получава в резултат от данни. Очакването е опит за предсказване - какво е най-вероятно да очакваме от следващия опит.  

На което и да е равномерно разпределение функцията на плътността е равномерна. Кое е очакването - средното. 

Тука идва термина математическо очакване Expected value - начин да кажем какво бихме очаквали от едно разпределение. 

Искаме да моделираме някакъв процес. 
На този процес подаваме данни - така направени, че да имат смисъл.
След подаване на данните получаваме някакви резултати. 
Ние си мислим, че този процес може да бъде моделиран - тоест да има някаква функция на входните данни, която да връща подобни резултати. 
Имаме намесени случайности. 
Затова подаваме същите данни на нашата функция. Реалните резултати са observed, a получените от функцията данни наричаме estimated/predicted.
Тази функция има много настройки. Гаусовото разпределене например има мю и сигма.
Това са настройки, които даваме предварително. Те имат някакво значение. 
Събираме колекционираме в един голям вектор. Така отделяме входната променлива X от предварителните настройки. 
С различни стойности на тези предварителни настройки можем да направим много различни модели.
Дори само от наблюдение може да разберем дали един модел е добър или калпав. Обаче ако мога да разбера доколко хиперпараметрите, които съм избрал, водят до разпределение, което прилича на оргиналното, това ще бъде моята мярка за правдоподобие - likelyhood. 
Likelihood - колко добре модел, който съм си представял за данните, описва данните в реалния случай. 
Ако мога да опиша тази интуиция - Likelihood function. 
Тя трябва да приема като аргументи observed, predicted. Ама те predicted идват от входните данни, и настройките. 
И тази функцията казва колко близко е зелената функцията до жълтия резултат. 
Това ако може да го определим Likelyhood function. Ако можем да го направим, може да сравняваме различните модели.
Ще си играем с различни хиперпараметрите и да сравним кой е по-правдоподобния от тях. 
Така че се опитваме да максимизираме тази функция, да потърсим хиперпараметрите, за да намерим този, при които този модел е най-добър. 
Това е друга гледна точка към Machine Learning. 
Максимизирането на една функция означава да търсим производните - първата да 0, втората да е < 0 - локален максимум.
Mistral 7 - параметрите са 7 милиарда. 
Трябва да знаем каква задача решаваме. 
maximum likelihood estimation. 

Обвързваме правдоподобието с формулата на бейс. 
Интересува ни концепция - имаме модели за данните и можем да разберем дали един модел е по-добър от друг. 
Данните са фискирани. 
Търсим производните на функцията спрямо всички параметри - получаваме вектор, с всички производни на лос функцията спрямо тита. 
maximum likelihood estimation for linear regression.  

За всяка една функция за моделиране трябва да подаваме числа, матрици от числа - правоъгълна таблица. 


