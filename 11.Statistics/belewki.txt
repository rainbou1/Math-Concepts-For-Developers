Поне един jupyter notebook с :
Анализ на задачата.
Математика
Код.

Методите на работи и начина на работа.
Трябва да пишем цитирания, а не че са наши собствени мисли.

Много често въпрос какво представлява линейна функция
Може да се смятат производни.
jupyter notebook.
Някоя дефиниция.
Scientific citation. Scientific citation generator. 
arxiv.org Цитат може да включва Document Object Identifier.
В края на Jupyter notebook се слага bibliography или references. 

===================================================================
bias = пристрастие, склонност, наклон.

Добре написано дърво на хъфман би трябвало да има ниво 5. Демо е 1

Science of analyzing data:
Ако броя на експериментите клони към безкрайност, но и тогава и броя на успешните клонят към безкрайност. Но те винаги са по-малко или равно на общия брой.
Group theory - изследване на симетрия.
Measure theory - приложения в статистиката.
law of large numbers - всяка случайна величина, когато я измерваме повече и повече пъти, някои нейни характеристики като средно аритметично се стабилизират.
Знанието, че нещо се е случило, ограничава търсенето за него.
Въвеждаме условна вероятност. Когато знаем, че B е станало, се ограничаваме само до случаите, когато В е валидно.
Намаляване на броя на изходите. Намаляване интропията. 

Зад всяко едно число стои доверителен интервал. 
Статистика е наука за количествено и качествено определяне на характеристики на случайни променливи. 
Правим много на брой наблюдения, виждаме какво се е случило, и се питаме доколко това дето се е случило ни е изненадало. Защото за да ни изненада нещо трябва да имаме очакване за него.(хипотеза).
Стигаме до въпроса дали задачата въобще е решима. 
One statistic е едно от числата, с които описваме някакво случайно събитие. Например минималната стойност - например резултат от хвърляне на зарче.

data forecasting. 
Всички елементи, които се получават експериментално от една случайна променлива, се наричат съвкупност (population).
Може да се опитаме да правим приближения, апроксимации. Най-доброто, което можем да направим, е да предположим, че поведението на малкото данни ще е подобно на много данни. 
Тези малко данни се наричат sample, извадка. И оттам идва идеята за семплиране от едно разпределение.
Взимаме едно число от това разпределение. То има вероятност. 
Законът за големите числа не работи за малки и това не може да го докажем.
Statistical bias - когато имаме bias означава че не сме отчели нещо.
Преглъщаме възможността нашата извадка да не бъде представителна, свойствата и да не наподобяват много на тези на съвкупността.
Една голяма част от работата ще бъде да търсим такива bias-и. 
Теорема на Гьодел - никоя система, която е консистентна, не може да каже за себе си, че е консистентна.
Absence of evidence is not evidence of absence - липса на доказателство не е доказателство на липса. 
Тогава въпроса е как създаваме извадка. - scientific method. 
Един експеримент трябва да е контролиран - тоест да тестваме конкретно нещо в изолирана среда. Но не винаги е възможно. Затова понякога правим само наблюдения. 

Цялата ни съвкупност - избираме от нея една част, която е по някакъв начин достъпна - sampling frame. И от тази sampling frame може да взимаме много samples. 
Една грешка може да е от създаването на sampling frame - грешно предположение.
Втора грешка може да е от случайна неопределеност на данните - несигурност. random error, variant - случайна неопределеност в данните. 
Основен метод за семплиране - случайно семплиране.- random sampling. - с равномерно разпределение или равна вероятност. 
за случайни величини - i.i.d - independent and identically distributed - независими са една от друга имат еднакви разпределения. 
Stratified sample - разслоено - възрастови групи например. От всяка една група ще получим достатъчно количество примери.
Cluster sample. 

Абсолютно всеки път оставяме възможност това което наблюдаваме, да е неправилно. 

работа с Dataset
- има данни и мета данни - данни за данните. Обикновено данните са в таблица.
Descriptive statistics. 
CSV file - всяка една колона представлява една променлива за всеки 1 филм. Всеки един вектор стълб е едно измерение към данните. 
Това е едно 12 мерно пространство е всеки запис е 1 точка в това пространство. 
Има променливи са категорийни и някои от тях са числови. 
Всяка една колона има 1 тип данни. 
Индексиране с името на колоната ["release_year"]
Филтриране в pandas
Може да се филтрира по повече от едно условие, но тогава се ползват "&" "|" "~". и тъй като има приоритет, се слагат в скоби.
Average - мярка за типична стойност.
Mean - arithmetic mean - средно аритметично. 
Средно на година имаме 119 филма. Средно аритметично се смята сума върху брой. Означава се с черта отгоре.

X черта е средното аритметично от извадка.
Ако имаме данни за цялата съвкупност, то с мю черта означаваме средното аритметично на съвкупността. Нарича се така заради гаусовото разпределение. 
Закон за големите числа - реално казва, че ако броя на записите е голям, средното на огромната извадка наподобява средното на съвкупността. 

Медиана - медианата на един data set е стойността на средния елемент на сортирани данни. Когато не е точно определен, взимаме средното аритметично на двата средни елемента.
np.mode() - връща най-често срещаната стойност. Ако има повече от 1 такава стойност, се нарича бимодално разпределение. Много често се оказва, че е генерирано от две други, които са били събрани. 
Има хармонична прогресия.
За един dataset има неравенства. 
QM- AM- GM- HM Inequalities.
Какво означава централна тенденция?
probability density function - площта на цялата графика е 1. 

Как да характеризираме типичната разлика от центъра - Говорим за sample. Ако говорим за съвкупност, е мю.
Това отдалечаване има два измерителя. 
Едното е var(). 
Се нарича дисперсия. Корен квадратен - стандартна грешка или ако е само извадка - стандартно отклонение.
.std() - standard deviation. 
Това е мярка за това колко е разпръснато разпределението. 

При гаусовото разпределение. 
сигма е стандартното отклонение. 
Стандартно гаусово разпределение - мю е 0, сигма е 1.
Може да имаме мю = 5.
Може да имаме мю = 0 и по-голяма сигма. 
Сигма е > 0 .
Може да превърнем някакво гаусово разпределние - например мю = 5, сигма = 0,7. Може да го превърнем в стандартното - със мю = 0, сигма = 1.
това което трябва да направим е от всяка една стойност да извадим средното и да разделми на стандартното отклонение. 
x - мю/сигма.
Този начин за превръщане на някакво разпределение в стандартното се нарича Z-score.
По този начин постигаме еднакъв поглед върху различни неща.
Процеса се нарича standardization.

Оказва се, че средното и дисперсията са само двете страни на една малко по-обща характеристика на данни. 
Central moment of distribution.
Използват се различни степени.
3 - нарича се на български асиметрия, на английски skewness.
4 - kurtosis. Ексцес на български.

Гаусово разпределение има асиметрия 0.
Да видим нашето колко има
number_of_movies_per_year.skew()
Има положителна и отрицателна асиметрия.
при kurtosis. pandas.DataFrame.kurtosis - тука говорим за колко широко или тясно е едно разпределение.
leptokurtic разпределение.
Ако има много стойности далече от центъра, то нашто разпределение прилича на плато. platokurtic.
Подробност - по стандартната дефиницията на гаусовото разпределение ексцес е 3. 
number_of_movies_per_year.kurt()

mean, std, skew, kurt - първите 4 момента на това разпределение. Нулевия винаги е 1. 
Ексцеса има приложение да разберем кога едно разпределение е много тясно. Говорим за колко вероятност има в центъра спрямо в опашките. Може да имаме разпределения, които имат много малко неща в опашките, но самите им опашки продължават много дълго. 

Може да характеризираме разпределенията с five number summary.
netflix_titles.describe()
Във всяка една част има по 1/4 от филмите.
Процентил.

plt.bloxplot(netflix_titles.release_year)
plt.show()
Четерите части се наричат quartile.
Interquartile Range. 

Тези неща се използват при сравняване на разпределения.

Категории 
====================================
Категорийна променлива е такава, която има ограничен брой стойности. 
netflix_titles.type.value_counts()
По категории се опитваме да групираме и да видим какво става във всяка една група.

from sklearn.datasets load 
Променливите могат да бъдат категорийни и числови в диабет сета.
Взаимодействие на две променливи - едната като се промени, влияе върху другата - доколко двете се движат заедно.
Тогава едната променлива я слагаме по x, другата по y, и всяка стойност я слагаме точка.
plt.scatter(ldl, hdl)
Нямаме хора, при които bmi и hdl са едновременно големи. 
Питаме се колко свързани са тези променливи.
Ако видим колко е типичното разстояние на едната спрямо типичното разстояние от центъра на другата, може да видим доколко тези променливи варират заедно - колко е тяхната ковариация.
covariance.
np.corrcoef - получаваме коефицициенти на корелация. - Pearson's - изследва доколко между 2 променливи има линейна връзка..
Когато е положителна, значи когато едната променлива се променя, променя се и другата.
= 1 абсолютно линейна.
колкото по-близо е до 0, значи няма корелация.

np.cov - ковариацията на една променива със себе си е нейната дисперсия.

!!! Correlation does not imply causation  - ако между 2 променливи има корелация, това не означава, че има причинно-следствена връзка.
Визуализацията е много важна.
Ancombe dinosaur - dataset.
bias - тенденция, наклонност. 
Историята с Бъркли - Данните ни казват нещо, ама истината е наобратно.
Причините са:
1. Изпускаме нещо
2. Неравномерни извадки. 

Агрегирани данни - много пъти осреднявани, групирани, събрани. 
Как взимаме средно на средни.

Имаме вариант, дето някакви данни не ги събираме и ги изпускаме завинаги. 
Затова винаги правим възможно много данни и променливи. 
Spurious correlations - започваме да виждаме неща, дето ги няма. 

Cognitive biases.
Нашият мозък обича да го мързи и затова се подвежда.

Проблемно е да кажем кога една корелация е силна или слаба.
