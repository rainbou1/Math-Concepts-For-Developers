Научния метод се базира на хипотези и тяхната проверка.
Scientific method.
Въпрос -> Проучване (важна стъпка, която не трябва да пропускаме) -> Хипотеза -> Експеримент
Много важно е да можем да правим експерименти.
Всичките тези неща не работят, ако няма хипотези. Създаването на хипотези е най-важния момент.
Thesis - твърдение.
Директния превод е предположение - хипотеза.
Важно е това което предполагаме да може да бъде проверено и да може да бъде отхвърлено - to be falsifiable.
Machine Learning е създаване и тестване на хипотези. Такива познания какво правим, какво гарантираме и не можем да гарантираме е много важно.
Един ML модел представлява хипотеза за данните.

Доверителен интервал и доверителни нива.
Статистиката не работи само за 1 sample/наблюдение.
Вероятностите представляват математическата граница при безкраен брой експерименти.
Но нямаме време и затова се задоволяваме с краен брой и дори много ограничени данни, които наричаме извадки.
Всичките данни, които бихме могли да получим, наричаме съвкупност или population, а ваденето на тази по-малка колекция от данни извадка.
При увеличаване на размера на извадката характеристиките и приближават тези на съвкупността.
Когато говорим за характеристиките винаги има някаква несигурност.

Пример за доверителен интервал и ниво:
Една случайна променлива има безкрайно много стойности.
Всяко едно събитие, което  има вероятност  > 0 да се случи, все някога ще се случи.
Едно гаусово разпределение. - всички свойства са характерни за него. Може да получим всички числа от -безкрайност до +безкрайност. 
!!!! Когато имаме непрекъсната вероятност, не може да говорим за вероятност за число.

P(x = lambda) = 0, lambda е елемент на реалните числа.
Говорим за вероятност в интервала - а, а+h, h клонящо към 0 и h = 0 са много различни. 
Това е като скоростта - 

Трябва да намерим баланса между - много точното, но много безполезно - всяка една стойност е вероятно, и между вероятност за конкретно число = 0 търсим баланс.
Търсим баланс с търсене на площ.

Може да питаме вероятността да е 1 = probability density function.
Питаме площта между едната стойност и другата стойност. 
Може да си избираме интервал между а и б - интеграла. Този интервал съдържа някакъв процент от площта под кривата. Цялата площ е 100% по дефиниция.
Доверителен интервал е този, в който избираме да работим. В който искаме да разберем колко на брой стойности има.
Ще можем да питаме една стойност от това разпределение е между a и b. И правим а и b каквито си искаме. 
Ако искаме голяма голяма вероятност, тоест голяма площ, може би ще се ориентираме към максимума на разпределението. 
Ще говорим за вероятност в термините на интервалите.
Confidence interval. 
Честотна дефиниция на вероятност. 
Confidence level - доверително ниво .самата вероятност, - колко пъти сме получили число в този интервал спрямо колко пъти сме получили число общо.
Колкото по-голямо е, толкова е по-добре.
По-тесен интервал означава по-малка вероятност.
По-голям интервал означава по-голяма увереност, но пък няма да е толкова полезно.

В примера взимаме като разлика на 2 площи. - Площта на графиката от - безкрайност до 1] - площта на графиката от - безкрайност до -2
Кумулативни функции cdf. Стандартно гаусово разпределение. При гаусовото разпределение стандартното отклонение е 1. 
Нещо става с увереност 3 сигма. 
Независимо колко голямо стандартно отклонение вземем, има винаги шанс ненулева вероятност за екстремно големи или малки числа. 
Никога не се доверявайте само на 1 число. 
heights.skew()
heights.std() - standart deviation. - разстояние от центъра. 
между 158 и ...имаме едно стандартно отклонение разлика. 
Стандартното отклонение се смята като разстояние от средното.
heights.mean() - heights.std(), heights.mean() + heights.std()

Знаем какво е Z scores - като му извадим средното мю и разделим на стандартното отклонение сигма, да получим нормализирана версия, която има гаусово разпределение със стандартните параметри. 
X пак има гаусово разпределение, ама с други числа.

Cdf - ни дава проценти вероятност.
percent point function - inverse of cdf.
Имаме случайно с някакво разпределение. 

Ще питаме колко е значима една стойност.
Нямаш теория, имаш хипотеза - предположение.
Предполагам, че нещо се случва, предполагам нещо за данни. 
Теория е комбинация от много на брой продължително време проверявани хипотези. 
Факт е нещо, което наблюдаваме. Например запис в dataset. Може да е резултат от експеримент.
Закон е нещо което описва вече съществуваши взаимовръзки, отношения. Нещо което не е нужно да бъде обяснявано. Намерили сме някакъв pattern. Но това че знаем какво е не значи че може да го обясним. 
Три вида хипотези - attributive, associative, causal. 

Всеки път като формулираме хипотези, ще формулираме двойка хипотези. Те си противоречат. 
Null hypothesis.
Alternate hypothesis.
парадокс на симпсън confounding variable - дето ни се бърка в работата.

Хипотезата, че нищо интересно няма, не е вярна.
bias в данните - голям проблем.
методи за откриване на проблеми.
Формулираме нулева хипотеза и ще се опитаме да я отхвърлим.
От две реалности и две действия които предприемаме - имаме 4 комбинации, но само 2 от тях са верни.
Да не отхвърлим нулевата хипотеза не означава, че я приемаме.
А пък ако я отхвърлим не означава че приемаме другата хипотеза.
negative и positive са свързани с действието, което предприемаме. Те са функция на действието, което сме решили да направили.
Таблицата се нарича confusion matrix.

Ще се опитаме да отхвърлим нулевата хипотеза - тоест че това което се наблюдава не е чиста случайност и че има нещо интересно.
P(FP) не може да е 0.
ама нека P(FP) = 1%.
тези експерименти се повтарят.
Трябва да гарантираме, че резултатите може да бъдат репродуцирани.

P(FP) - колкото по-малко е толкова по-стрикни сме и сме толкова по-уверени, че е малко вероятно да сбъркаме.
За да разберем какво става въпрос, трябва да си изберем test statistic.
Избираме максимален толеранс за false positive, наречен алфа.